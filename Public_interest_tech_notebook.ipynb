{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempt to project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stevie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sqlite3 import Error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sqlite3\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   organizations  120000 non-null  object\n",
      " 1   services       120000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read in data frame.\n",
    "# Add extra repeat rows to make training set larger \n",
    "df = pd.read_csv('ac_sheet5.csv')\n",
    "df = pd.concat([df]*10000, ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stevie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "df['cleaned'] = df['services'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vectorizer for words in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 358)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(df['cleaned']).toarray()\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline thats transform data set to vector and place in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ACHSAM       1.00      1.00      1.00      2466\n",
      "      ACHSID       1.00      1.00      1.00      2464\n",
      "      ACHSPC       1.00      1.00      1.00      2533\n",
      "        ACRM       1.00      1.00      1.00      2506\n",
      "     GCAPFGP       1.00      1.00      1.00      2446\n",
      "      GCAPHS       1.00      1.00      1.00      2486\n",
      "     GCAPMIP       1.00      1.00      1.00      2523\n",
      "   GCAPWICAC       1.00      1.00      1.00      2504\n",
      "        SJAA       1.00      1.00      1.00      2528\n",
      "      SJGEAT       1.00      1.00      1.00      2460\n",
      "    VADVACSR       1.00      1.00      1.00      2513\n",
      "     VADVNRG       1.00      1.00      1.00      2571\n",
      "\n",
      "    accuracy                           1.00     30000\n",
      "   macro avg       1.00      1.00      1.00     30000\n",
      "weighted avg       1.00      1.00      1.00     30000\n",
      "\n",
      "[[2466    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 2464    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 2533    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 2506    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 2446    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0 2486    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0 2523    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0 2504    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 2528    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 2460    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 2513    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0 2571]]\n"
     ]
    }
   ],
   "source": [
    "#first we split our dataset into testing and training set:\n",
    "# this block is to split the dataset into training and testing set \n",
    "X = df['cleaned']\n",
    "Y = df['organizations']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "# instead of doing these steps one at a time, we can use a pipeline to complete them all at once\n",
    "pipeline = Pipeline([('vect', vectorizer), #Preprocessor\n",
    "                     ('chi',  SelectKBest(chi2, k=300)), #Feature Selection\n",
    "                     ('clf', RandomForestClassifier())]) #ML model type\n",
    "# fitting our model and save it in a pickle for later use\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "#with open('RandomForest.pickle', 'rb') as f:\n",
    "#    pickle.dump()\n",
    "ytest = np.array(y_test)\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it out with random services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean random service text before prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('ac_sheet6.csv')\n",
    "new_df['cleaned'] = new_df['services'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GCAPMIP', 'VADVACSR', 'GCAPMIP', 'VADVACSR', 'GCAPMIP', 'GCAPMIP'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_df['services'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('ac_sheet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organizations</th>\n",
       "      <th>services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volunteers of America Delaware Valley-Navigati...</td>\n",
       "      <td>job training, educational placement , employme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atlantic City Rescue Mission:</td>\n",
       "      <td>Emergrency Shelter for men, women, and mothers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gateway Community Action Partnership: WIC-Atla...</td>\n",
       "      <td>Pregnant Postpartum Women, Infants, and Childr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volunteers of America Delaware Valley: Atlanti...</td>\n",
       "      <td>linkage to mental health and substance abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gateway Community Action Partnership: Foster G...</td>\n",
       "      <td>Intergenerational Program Senior Volunteer Opp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AtlantiCare Health Services FQHC Adult Medicine</td>\n",
       "      <td>We treat all patients, regardless of their ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AtlantiCare Health Services FQHC Pediatric Clinic</td>\n",
       "      <td>substance abuse detox and management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AtlantiCare Health Services FQHC Infectious Di...</td>\n",
       "      <td>mental health services, care for diabetes, ast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gateway Community Action Partnership Head Star...</td>\n",
       "      <td>Early Childhood Education servicing Families w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gateway Community Action Partnership Male Init...</td>\n",
       "      <td>Fatherhood parenting support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>South Jersey AIDS Allliance</td>\n",
       "      <td>For People Living with HIV AIDS case managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>South Jersey Gas Energy Assistance Team</td>\n",
       "      <td>The South Jersey Gas Energy Assistance Team ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        organizations  \\\n",
       "0   Volunteers of America Delaware Valley-Navigati...   \n",
       "1                       Atlantic City Rescue Mission:   \n",
       "2   Gateway Community Action Partnership: WIC-Atla...   \n",
       "3   Volunteers of America Delaware Valley: Atlanti...   \n",
       "4   Gateway Community Action Partnership: Foster G...   \n",
       "5     AtlantiCare Health Services FQHC Adult Medicine   \n",
       "6   AtlantiCare Health Services FQHC Pediatric Clinic   \n",
       "7   AtlantiCare Health Services FQHC Infectious Di...   \n",
       "8   Gateway Community Action Partnership Head Star...   \n",
       "9   Gateway Community Action Partnership Male Init...   \n",
       "10                        South Jersey AIDS Allliance   \n",
       "11            South Jersey Gas Energy Assistance Team   \n",
       "\n",
       "                                             services  \n",
       "0   job training, educational placement , employme...  \n",
       "1   Emergrency Shelter for men, women, and mothers...  \n",
       "2   Pregnant Postpartum Women, Infants, and Childr...  \n",
       "3        linkage to mental health and substance abuse  \n",
       "4   Intergenerational Program Senior Volunteer Opp...  \n",
       "5   We treat all patients, regardless of their ins...  \n",
       "6                substance abuse detox and management  \n",
       "7   mental health services, care for diabetes, ast...  \n",
       "8   Early Childhood Education servicing Families w...  \n",
       "9                        Fatherhood parenting support  \n",
       "10  For People Living with HIV AIDS case managemen...  \n",
       "11  The South Jersey Gas Energy Assistance Team ho...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = {'aids help'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt = { \"blair prepares to name poll date tony blair is likely to name 5 may as election day when parliament returns from its easter break  the bbc s political editor has learned.  andrew marr says mr blair will ask the queen on 4 or 5 april to dissolve parliament at the end of that week. mr blair has so far resisted calls for him to name the day but all parties have stepped up campaigning recently. downing street would not be drawn on the claim  saying election timing was a matter for the prime minister.  a number 10 spokeswoman would only say:  he will announce an election when he wants to announce an election.  the move will signal a frantic week at westminster as the government is likely to try to get key legislation through parliament. the government needs its finance bill  covering the budget plans  to be passed before the commons closes for business at the end of the session on 7 april.  but it will also seek to push through its serious and organised crime bill and id cards bill. mr marr said on wednesday s today programme:  there s almost nobody at a senior level inside the government or in parliament itself who doesn t expect the election to be called on 4 or 5 april.  as soon as the commons is back after the short easter recess  tony blair whips up to the palace  asks the queen to dissolve parliament ... and we re going.  the labour government officially has until june 2006 to hold general election  but in recent years governments have favoured four-year terms.\"}\n",
    "txt = {'aids help'}\n",
    "df1 = pd.DataFrame(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GCAPMIP'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
